---
categories: Pytorch
title: Pytorch中的常用向量操作
---

#  `torch.gather`

函数声明为：

```python
torch.gather(input, dim, index, out=None, sparse_grad=False) → Tensor
```

函数作用为：

> Gathers values along an axis specified by dim. 

$$\begin{array}{l}{\text { If input is an n-dimensional tensor with size }\left(x_{0}, x_{1} \ldots, x_{i-1}, x_{i}, x_{i+1}, \ldots, x_{n-1}\right) \text { and dim }=i, \text { then index must be }} \\ {\text { an } n \text { -dimensional tensor with size }\left(x_{0}, x_{1}, \ldots, x_{i-1}, y, x_{i+1}, \ldots, x_{n-1}\right) \text { where } y \geq 1 \text { and out will have the same }} \\ {\text { size as index. }}\end{array}$$

举个例子：

```python
t = torch.tensor([[1, 2], [3, 4]])
#tensor([[3, 4],
#        [1, 2],
#        [1, 4]])
torch.gather(t, 0, torch.tensor([[1, 1], [0, 0], [0, 1]]))
```

由于输出张量和*index*张量有着相同的形状，所以我们可以做以下直观的理解：

![](../../../img/gather.png)

#  `torch.unsqueeze`

函数声明为：

```python
torch.unsqueeze(input, dim, out=None) → Tensor
```

函数的作用为：

> Returns a new tensor with a dimension of size one inserted at the specified position. 

可以理解为使得这个张量在指定的位置增加一维，例子如下：

```python
# create a tensor
x = torch.tensor([1, 2, 3, 4])

# insert a dimension in dim 0
torch.unsqueeze(x, 0)
# tensor([[ 1,  2,  3,  4]])

# insert a dimension in dim 1
torch.unsqueeze(x, 1)
# tensor([[ 1],
#        [ 2],
#        [ 3],
#        [ 4]])
```

#  `torch.squeeze`

函数声明为：

```python
torch.squeeze(input, dim=None, out=None) → Tensor
```

函数作用为：

> Returns a tensor with all the dimensions of `input` of size 1 removed. 

可以理解为返回一个张量，这个张量所有size为1的维度都将被去除，如果给定了*dim*，那么我们将会只去除这一维度（如果这一维度size为1）：

```python
>>> x = torch.zeros(2, 1, 2, 1, 2)
>>> x.size()
torch.Size([2, 1, 2, 1, 2])
>>> y = torch.squeeze(x)
>>> y.size()
torch.Size([2, 2, 2])
>>> y = torch.squeeze(x, 0)
>>> y.size()
torch.Size([2, 1, 2, 1, 2])
>>> y = torch.squeeze(x, 1)
>>> y.size()
torch.Size([2, 2, 1, 2])
```

#  `torch.Tensor.view(*shape) `

函数声明为：

```
torch.Tensor.view(*shape) → Tensor
```

函数作用为：

> Returns a new tensor with the same data as the `self` tensor but of a different `shape`. 

即为保持原张量的数据不变，变化张量的形状。

```python
>>> x = torch.randn(4, 4)
>>> x.size()
torch.Size([4, 4])
>>> y = x.view(16)
>>> y.size()
torch.Size([16])
>>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
>>> z.size()
torch.Size([2, 8])
```



