---
categories: 强化学习
title: 强化学习调参技巧
---

- 有些神经网络在加了Batch Normalization后会出现一些输出为NaN的情况，需要注意；
- EPSILON DECAY设置的比较慢时，随机决策会比较多，会导致训练变慢；当设置比较快时，会导致环境的探索能力不强，可能无法达到最优；
- 输出不需要激活函数。

# DQN

- 当存在负回报时，注意神经网络中的激活函数ReLU可能出现不激活的情况；
- 当存在执行某动作出现状态自转移时，可以设置负回报来进行惩罚。